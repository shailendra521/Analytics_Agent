import os
from dotenv import load_dotenv
from langchain_core.tools import tool
from langchain_core.prompts import PromptTemplate
import pathlib 
import numpy as np 
import pandas as pd
import re
from langgraph.graph.message import add_messages
from typing_extensions import TypedDict
from typing import Annotated , List , Optional , Tuple ,  Union
from langgraph.graph import StateGraph, START, END
from pydantic import BaseModel ,  Field
from langchain_community.utilities import SQLDatabase
from IPython.display import Image
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage
from langchain_openai import AzureChatOpenAI
from langchain_community.agent_toolkits import SQLDatabaseToolkit
import re

load_dotenv() 

def agent():
    model = AzureChatOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_API_BASE"),
    azure_deployment="gpt-4o-mini",
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    temperature=0.2
    )
    db = SQLDatabase.from_uri("mysql+pymysql://root:test@localhost:3306/employees")

    def clean_sql_query(raw_query: str) -> str:
        # Remove Markdown code fences like ```sql or ```
        cleaned = re.sub(r"```(?:sql)?\s*", "", raw_query, flags=re.IGNORECASE)
        cleaned = re.sub(r"\s*```", "", cleaned)
        return cleaned.strip()
    
    def sql_db_query_filter(raw_query: str) -> str:
        # Remove Markdown code fences like ```sql or ```
        cleaned = re.sub(r"```(?:sql)?\s*", "", raw_query, flags=re.IGNORECASE)
        cleaned = re.sub(r"\s*```", "", cleaned)
        return cleaned.strip()
    
    def extract_sql_error_info(error_string: str) -> Optional[Tuple[str, str]]:
        """
        Extracts the error type and error message from a SQLAlchemy-style error string.
    
        Returns:
            A tuple (error_type, error_message) if matched, otherwise None.
        """
        match = re.search(
            r"\(?(?P<error_type>[\w\.]+)\)?\s*\((?P<code>\d+),\s*\"(?P<error_message>.*?)\"\)", 
            error_string
        )
        if match:
            return match.group("error_type"), match.group("error_message")
        return None
    
   
    toolkit = SQLDatabaseToolkit(db=db, llm=model)
    sql_db_query , tables_schema_tool , _ , sql_db_query_filter= toolkit.get_tools()
    
    class Column(BaseModel):
        column_name: str = Field(..., description="Name of the column")
        column_description: str = Field(..., description="Describe the column in one line")
        table_name: str = Field(..., description="Name of the table the column belongs to")

    class Columns(BaseModel):
        columns: List[Column]

    
    class ColumnRelation(BaseModel):
        column1_name: str = Field(..., description="Name of the first column")
        column1_table: str = Field(..., description="Table that the first column belongs to")
        column2_name: str = Field(..., description="Name of the second column")
        column2_table: str = Field(..., description="Table that the second column belongs to")
        relation: str = Field(..., description="How the two columns are related, e.g., foreign key, join condition, etc.")

    class ColumnRelations(BaseModel):
        column_relations: List[ColumnRelation]

    class State(TypedDict):
        query: Annotated[str,"question asked by client"]
        final_answer: Annotated[str,"final answer generated by agent"]
        is_read_query:  Annotated[bool,"verify query is read type or not"]
        relevant_tables: Annotated[list[str],"name of tables used in query"]
        dialect: Annotated[str,"tell which database type query to generate"]
        columns_relations: Annotated[ColumnRelations,"relation between columns used for writing joining query"]
        relevant_columns: Annotated[Columns,"columns extracted by agent in order to use in query"]
        top_k: Annotated[int,"Limit parameter for sql query"]
        sql_query: Annotated[str,"sql query generated by the agent"]
        query_result: Annotated[str,"query result from databse"]
        error_messages:Annotated[list, add_messages]
        retry_counter:Annotated[int,"number of times graph will retry to fix the error"]
        conversation: Annotated[
            List[Union[AIMessage, HumanMessage, SystemMessage]],
            "Conversation history between AI and Human"]
        summary: Annotated[str,"summary of the query"]
        type_of_output: Annotated[str,"type of output to be returned to the user aggreate or plot"]
        plot_type: Annotated[str,"plot to be made"]
        node: Annotated[str,"node name"]

    class query_checker(BaseModel):
        is_read_query: bool


    check_query_template = """
        You are a query analyzer.

        The user provides a query in natural language.

        Your task is to determine whether the query is related to **reading data** (e.g., retrieving, showing, listing, or selecting information).

        - Return **True** if the query is a read operation.
        - Return **False** if it is a write operation (e.g., insert, update, delete, create, drop).

        Query: {query}
        """
    
    check_query_template_prompt = PromptTemplate.from_template(check_query_template)
    check_query_model = check_query_template_prompt | model.with_structured_output(query_checker)

    def check_python_query(state:State) -> State:
        """
        In this function models tells if the query is related to read or not.
        """
        print("*"*35)
        print("Query Checker Node")
        print("*"*35)
        resp = check_query_model.invoke(state["query"])

        if resp.is_read_query:
            return {"is_read_query": True , "node":"query_checker"}

        return {"final_answer": "Query is not related to read" , "is_read_query": False , "node":"query_checker"}


    def query_checker(state:State) -> State:
        """
        function takes decision to end the process or not based on query
        """
        if state["is_read_query"]:
            return "select_relevant_tables"
        else:
            return END
        
    
    class RelevantTables(BaseModel):
        relevant_tables: List[str]

    relevant_tables_template = """
    You are a query analyzer.

    You are given:
    - A user query written in natural language.
    - A list of all table names in a database.

    Your task is to identify which tables are most relevant to answering the query.

    Return a Python list of the relevant table names (exact matches from the list).

    Query:
    {query}

    Available Tables:
    {available_tables}

    Relevant Tables (as a Python list):
    """

    relevant_tables_prompt = PromptTemplate.from_template(relevant_tables_template)
    relevant_tables_model = relevant_tables_prompt | model.with_structured_output(RelevantTables)

    def Select_table_relevant_tables(state:State) -> State:
        """
        This function selects the relevant tables from the database.
        """
        print("*"*35)
        print("Relevant Tables Node")
        print("*"*35)

        resp = relevant_tables_model.invoke({"query": state["query"], "available_tables": db.get_usable_table_names()})

        return {"relevant_tables": resp.relevant_tables , "node":"select_relevant_tables"}
    
    extract_columns_template = """
        You are a query analyzer.
        you are provided with a query and a database schema.
        your task is to extract the columns used for answering the query

        Query:
        {query}

        Database Schema:
        {schema}

        """

    extract_columns_prompt = PromptTemplate.from_template(extract_columns_template)
    extract_columns_model = extract_columns_prompt | model.with_structured_output(Columns)



    def relevant_column(state:State) -> State:
        """
        This function extracts the columns and their relatioin with other useful columns
        """
        print("*"*35)
        print("Relevant Columns Node")
        print("*"*35)
        table_names_str = ", ".join(state["relevant_tables"])
        schema = tables_schema_tool.invoke({"table_names": table_names_str})
        resp = extract_columns_model.invoke({"query": state["query"], "schema": schema})
        return {"relevant_columns": resp.columns , "node":"relevant_column"}
    
    extract_column_relations_template = """
        You are a SQL query analyzer.

        Your task is to analyze a natural language query and a given database schema, and extract only the **column-to-column relationships** that would be needed to write a correct SQL query.

        For each relationship, identify:
        - The name of the two related columns
        - The tables those columns belong to
        - A description of how they are related (e.g., join condition, foreign key)

        Only include relationships that are directly relevant to solving the query.

        Query:
        {query}

        Database Schema:
        {schema}
        """


    extract_column_relations_prompt = PromptTemplate.from_template(extract_column_relations_template)
    extract_column_relations_model = extract_column_relations_prompt | model.with_structured_output(ColumnRelations)



    def column_relations(state:State) -> State:
        """
        This function extracts the columns and their relatioin with other useful columns
        """
        print("*"*35)
        print("columns relations Node")
        print("*"*35)
        table_names_str = ", ".join(state["relevant_tables"])
        schema = tables_schema_tool.invoke({"table_names": table_names_str})
        resp = extract_column_relations_model.invoke({"query": state["query"], "schema": schema})
        return {"columns_relations": resp.column_relations , "node":"column_relations"}


    class Steps(BaseModel):
        steps: List[str] = Field(..., description="Steps the LLM took in order to solve the query.")


    generate_cot_template_system_prompt = """
    You are a thoughtful and intelligent SQL query generation agent for a {dialect} database.
    Your task is to break down the user's question into a sequence of **open-ended reasoning questions**, following a logical and directed path to help construct a correct and efficient SQL query.
    ---
    ### Input:

    **User Question:**  
    {query}
    ---
    ### Instructions:
    - Generate a list of open-ended questions that guide the reasoning process step by step.
    - Do **not** provide answers, explanations, or SQL code.
    - Follow this sequence of reasoning directions when applicable:

    1. **Identify the relevant tables**: Ask what tables are involved in answering the user's question.
    2. **Identify the relevant columns**: Ask what columns are needed from each table.
    3. **Define relationships**: Ask how the tables are related (joins, foreign keys, etc.).
    4. **Determine filters/conditions**: Ask what filtering logic should be applied.
    5. **Check for aggregations**: Ask if aggregation (e.g., MAX, COUNT, SUM) is needed.
    6. **Check for query structure**: Ask if the query should be broken into modular steps (e.g., using CTEs or subqueries) to handle complexity or improve readability/performance.
    7. **Define sorting or limits**: Ask if the result needs ordering or limiting (e.g., top N).
    8. **Validate logic**: Ask how we ensure the query logic matches the user’s intent.
    9. **Check for potential inefficiencies or risks**: Ask if the query could result in infinite loops, Cartesian products, unbounded recursion, or missing indexes.
    10. **Summarize the logical structure**: Ask how the query should be logically structured based on the answers above (e.g., FROM → JOIN → WHERE → GROUP BY → ORDER BY).

    - You do not have to include all ten steps. If the user question is simple, fewer questions are acceptable — include only as many as are needed to logically solve the query.
    - Phrase each question naturally and clearly.
    - The **final question must always be**:  
      **"Can you summarize the logical steps and structure required to answer the query?"**

    ### Output Format:
    Return a plain Python list of strings (questions only).
    """

    system_message_for_cot_answer_template = """
    You are an expert SQL assistant.
    You are provided with the following context:

    **User Question:**  
    {query}

    **Relevant Columns:**  
    {relevant_columns}

    **Column Relationships (for JOINs):**  
    {columns_relations}

    ---
    ### Instructions:

    You will be asked questions by the user and should respond step-by-step, focusing on correctness, clarity, and performance.

    - Respond to one reasoning step at a time.
    - Always ground your answers in the provided schema and relationships.
    - Never invent tables, columns, or join logic.
    - Clarify user intent and data requirements precisely before suggesting query components.

    ### For Complex Queries:

    - Break logic into modular steps using **Common Table Expressions (CTEs)** where needed.
    - Use clearly named intermediary CTEs to improve readability and reusability, e.g.:
      - `FilteredEmployees`
      - `DeptMaxSalaries`
      - `JoinedResults`
    - Typical CTE steps may include:
      - Filtering by time, status, or attributes
      - Joining multiple related tables
      - Aggregating data (e.g., MAX, COUNT, AVG)
      - Ranking or selecting top values per group
    - Recommend **CTEs over repeated subqueries** for clarity and performance.

    ### Avoid These Pitfalls:

    - Cartesian joins (missing `ON` conditions)
    - Infinite or unbounded queries (no filters)
    - Filters or subqueries inside `WHERE` that repeat heavy logic
    - Joining historical tables (like `salaries`, `dept_emp`) without date constraints

    ### Output Format:

    - Do **not** return a full SQL query unless explicitly asked.
    - If asked to write the full query, structure it using CTEs with proper indentation and clear logic flow.
    - When asked to **summarize**, describe the intended logical query flow in natural language:
      - e.g., “First, filter employees hired after 2010; then join with salaries; then group by department to find the max salary.”

    """






    generate_cot_prompt = PromptTemplate.from_template(generate_cot_template_system_prompt)
    generate_cot_model = generate_cot_prompt | model.with_structured_output(Steps)

    query_correction_template = """
    You are a senior SQL engineer tasked with diagnosing and correcting a faulty SQL query for a {dialect} database.

    You are provided with:

    **User Question:**  
    {query}

    **Relevant Columns (with their tables):**  
    {relevant_columns}

    **Column Relationships (for JOINs):**  
    {columns_relations}

    **Previously Generated SQL Query:**  
    {generated_code}

    **Error Message (if any):**  
    {error_messages}

    **Database Schema:**  
    {db_schema}

    ---

    ### Your Tasks:

    1. **Analyze the error message carefully** and pinpoint the root cause (e.g., syntax issues, missing columns, logic errors, invalid joins).
    2. **Validate the logic** of the query based on the user question, the relevant columns, and the defined relationships.
    3. **Ensure all table and column names exactly match** those in the schema and follow correct aliasing.
    4. **Correct the SQL query** to satisfy the user's question.
    5. **Optimize the query for performance**, specifically:
       - Avoid full table scans
       - Prevent Cartesian products or infinite joins
       - Use appropriate filtering and aggregation
       - Consider using CTEs or window functions if they improve readability or efficiency
    6. Ensure the query **only returns accurate and necessary results**, matching the user's intent.

    ---

    ### Output:
    Return **only the corrected and optimized SQL query** (no explanation).
    """

    query_correction_prompt = PromptTemplate.from_template(query_correction_template)
    query_correction_model = query_correction_prompt| model


    def generate_sql_query_summary(state:State) -> State:
        """
        This function generates the SQL query from the state
        """
        print("*"*35)
        print("SQL Query Generation Summarizer Node")
        print("*"*35)

        resp = generate_cot_model.invoke({"query": state["query"], 
                                            "relevant_columns": state["relevant_columns"], 
                                            "columns_relations": state["columns_relations"], 
                                            "top_k": state["top_k"],
                                            "dialect":db.dialect,},
                                            )


        formatted_system_message_for_cot_answer_template = system_message_for_cot_answer_template.format(
            query=state["query"],
            relevant_columns=state["relevant_columns"],
            columns_relations=state["columns_relations"],
        )

        system_message_for_cot_answers = SystemMessage(content=formatted_system_message_for_cot_answer_template)
        helper_instructions = f"In case you need help with data, refer to the system prompts for column relationships, column names, and other schema details. If a final query is generated, use LIMIT {state['top_k']} as needed."

        messages = []
        messages.append(system_message_for_cot_answers)
        messages.append(HumanMessage(content=helper_instructions))
        for question in resp.steps:
            # Feed question as user message
            question = HumanMessage(content=f"{question}")
            messages.append(question)
            response = model.invoke(messages)
            # print("#"*40)
            # print(f"Q: {question}")
            # print(f"A: {response.content}")
            # print("#"*40)
            messages.append(AIMessage(content=response.content))

        return {"summary": messages[-1].content , "conversation":messages , "node":"generate_sql_query_summary"}
    
    sql_query_generate_prompt = """
    You are a senior SQL engineer tasked with generating a correct and efficient SQL query for a {dialect} database.
    
    You are provided with:
    
    **User Question:**  
    {query}
    
    **Relevant Columns (with their tables):**  
    {relevant_columns}  
    
    **Column Relationships (for JOINs):**  
    {columns_relations}
    
    **Summary of the logical steps and structure required to answer the query:**  
    {summary}
    
    Your task:
    
    - Write a clean, efficient SQL query that accurately answers the user’s question.
    - Use proper table aliases and clear formatting.
    - Use Common Table Expressions (CTEs) if it helps improve clarity or modularity.
    - Use only the provided columns and relationships — do not assume or invent schema information.
    - Add the following line at the end of the query to restrict the output:
      ```sql
      LIMIT {top_k} """


    sql_query_generate_prompt = PromptTemplate.from_template(sql_query_generate_prompt)
    sql_query_generate_model = sql_query_generate_prompt | model

    def generate_sql_query(state:State) -> State:
        """
        This function generates the SQL query from the state
        """
        if state.get("sql_query", "") and state.get("error_messages", []):
            print("#"*60)
            print("Not doing generation because query is generated")
            print("#"*60)
            table_names_str = ", ".join(state["relevant_tables"])
            schema = tables_schema_tool.invoke({"table_names": table_names_str})
            resp = query_correction_model.invoke({"query": state["query"],
                                                  "dialect":db.dialect, 
                                                  "relevant_columns": state["relevant_columns"], 
                                                  "columns_relations": state["columns_relations"],
                                                  "generated_code":state.get("sql_query",""),
                                                  "error_messages":state.get("error_messages",""),
                                                  "db_schema":schema})

            return {"sql_query": resp.content , "node":"generate_sql_query"}

        print("*"*35)
        print("SQL Query Generation Node")
        print("*"*35)
        resp = sql_query_generate_model.invoke({"query": state["query"],
                                                "relevant_columns": state["relevant_columns"],
                                                "columns_relations": state["columns_relations"],
                                                "summary": state["summary"],
                                                "dialect":db.dialect,
                                                "top_k":state["top_k"]})
        return {"sql_query": resp.content , "node":"generate_sql_query"}
    

    def filter_query(state:State) -> State:
        """
        This function filters the query to be a valid SQL query
        """
        print("*"*35)
        print("Filter Query Node")
        print("*"*35)
        return {"sql_query": clean_sql_query(sql_db_query_filter(state["sql_query"])) , "node":"filter_query"}
    
    def execute_query(state:State) -> State:
        """
        This function executes the SQL query
        """
        print("*"*35)
        print("Execute Query Node")
        print("*"*35)
        resp = sql_db_query(state["sql_query"])
        print("*"*35)
        print(resp)
        print("*"*35)
        return {"query_result": resp , "node":"execute_query"}
    
    def error_message_creator(state:State)->State:
        """
        This function extracts and formats the SQL error, storing it in the state.
        """
        print("*"*35)
        print("Inside error_message_creator Node")
        print("*"*35)
        error , message = extract_sql_error_info(state["query_result"])

        compiled_message = f"{error}:{message}"

        counter_value = state["retry_counter"] + 1
        return {"error_messages":[compiled_message],"retry_counter":counter_value , "node":"error_message_creator"}

    def query_error_handler(state:State)->State:
        """
        This function routes execution based on whether a SQL error occurred.
        Returns the next node name as a string.
        """

        try: 
            error , message = extract_sql_error_info(state["query_result"])
            if state["retry_counter"] > 3:
                print("*"*35)
                print("retry limit reached hence ending the graph execution")
                print("*"*35)

                return END

            if error:
                print("*"*35)
                print("Due to error angin generating code")
                print("*"*35)

                return "error_message_handler"
        except Exception as e:
            print("*"*35)
            print("since no error occured ending the code")
            print("*"*35)
            return "select_type_output"
    
    class TypeOfOutput(BaseModel):
        type_of_output: str = Field(..., description="Type of output to be returned to the user: 'aggregate' or 'plot'")
        plot_type: str = Field(..., description="Type of plot to be returned to the user if applicable; otherwise, None")

    prompt_select_type_output = """
    You are a query analyzer.

    You are given the following SQL query:
    {query}

    And its corresponding output:
    {query_result}

    Your task is to:

    1. Determine the type of output that should be returned to the user:
       - Is it an **aggregate** result (e.g., a single value or grouped summary)?
       - Or is it data that should be **visualized as a plot**?

    2. Make this decision by analyzing both the query and the result carefully.

    3. If a plot is appropriate, specify the **most suitable type of plot**:
       - For example: "bar", "line", "pie", "scatter", etc.

    4. If no plot is needed, set the plot type to `None`.
    """


    prompt_select_type_output_prompt = PromptTemplate.from_template(prompt_select_type_output)
    select_type_output_model = prompt_select_type_output_prompt | model.with_structured_output(TypeOfOutput)

    def select_type_output(state:State)->State:
        """
        This function selects the type of output to be returned to the user aggreate or plot
        """
        print("*"*35)
        print("Select Type Output Node")
        print("*"*35)
        resp = select_type_output_model.invoke({"query_result":state["query_result"],
                                                "query":state["query"]})
        return {"type_of_output":resp.type_of_output,"plot_type":resp.plot_type , "node":"select_type_output"}

    def path_decider(state:State)->State:
        """
        This function decides the path to be taken based on the type of output
        """
        if state["type_of_output"] == "aggregate":
            return "aggregate_result"
        else:
            return "plot_result"
        
    
    aggregate_result_template = """
        You are a query analyzer.

        You are given the following SQL query:
        {query}

        And its corresponding output:
        {query_result}

        Your task is to analyze the result and return a **natural language summary** that clearly communicates the conclusion of the query to a non-technical user.
        Be concise and accurate.
        """


    aggregate_result_prompt = PromptTemplate.from_template(aggregate_result_template)
    aggregate_result_model = aggregate_result_prompt | model


    def aggregate_result(state:State)->State:
        """
        This function returns the aggregate result to the user
        """
        print("*"*35)
        print("Aggregate Result Node")
        print("*"*35)
        resp = aggregate_result_model.invoke({"query":state["query"],"query_result":state["query_result"]})
        return {"final_answer":resp.content , "node":"aggregate_result"}
    
    def plot_result(state:State)->State:
        """
        This function returns the plot to the user
        """
        print("*"*35)
        print("Plot Result Node")
        print("*"*35)
        return {"final_answer":state["query_result"] , "node":"plot_result"}
    

    workflow = StateGraph(State)

    # nodes
    workflow.add_node("check_query", check_python_query)
    workflow.add_node("select_relevant_tables", Select_table_relevant_tables)
    workflow.add_node("relevant_column", relevant_column)
    workflow.add_node("column_relations", column_relations)
    workflow.add_node("generate_sql_query", generate_sql_query)
    workflow.add_node("filter_query", filter_query)
    workflow.add_node("execute_query", execute_query)
    workflow.add_node("error_message_handler",error_message_creator)
    workflow.add_node("generate_sql_query_summary",generate_sql_query_summary)
    workflow.add_node("select_type_output",select_type_output)
    workflow.add_node("aggregate_result",aggregate_result)
    workflow.add_node("plot_result",plot_result)


    # edges
    workflow.add_edge(START, "check_query")
    workflow.add_conditional_edges(
        "check_query",
        query_checker,
        [END , "select_relevant_tables"]
    )
    workflow.add_edge("select_relevant_tables", "relevant_column")
    workflow.add_edge("relevant_column", "column_relations")
    workflow.add_edge("column_relations", "generate_sql_query_summary")
    workflow.add_edge("generate_sql_query_summary", "generate_sql_query")
    workflow.add_edge("generate_sql_query", "filter_query")
    workflow.add_edge("filter_query", "execute_query")
    workflow.add_conditional_edges("execute_query",query_error_handler,[END,"select_type_output","error_message_handler"])
    workflow.add_edge("error_message_handler","generate_sql_query")
    workflow.add_conditional_edges("select_type_output",path_decider,["aggregate_result","plot_result"])
    workflow.add_edge("aggregate_result",END)
    workflow.add_edge("plot_result",END)

    graph = workflow.compile()

    return graph


        


    






